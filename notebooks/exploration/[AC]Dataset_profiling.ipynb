{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH_ROOT = Path.cwd().parents[1].resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH_ROOT / \"data\" / \"datasets\" / \"combined_dataset.csv\", index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "        annotator  \\\n0  A3BCGN11HDM8QR   \n1  A3SQ00HYQN7FYB   \n2    A5WAWW70PYRP   \n\n                                                                                                                                                               text1  \\\n0  and he sent eliakim who was over the household and shebna the scribe and the elders of the priests covered with sackcloth unto isaiah the prophet the son of amoz   \n1  and he sent eliakim who was over the household and shebna the scribe and the elders of the priests covered with sackcloth unto isaiah the prophet the son of amoz   \n2  and he sent eliakim who was over the household and shebna the scribe and the elders of the priests covered with sackcloth unto isaiah the prophet the son of amoz   \n\n                                                                                                                                               text2  \\\n0  and he sent eliakim who was over the house and shebna the scribe and the chief priests dressed in haircloth to isaiah the prophet the son of amoz   \n1  and he sent eliakim who was over the house and shebna the scribe and the chief priests dressed in haircloth to isaiah the prophet the son of amoz   \n2  and he sent eliakim who was over the house and shebna the scribe and the chief priests dressed in haircloth to isaiah the prophet the son of amoz   \n\n   label      dataset  random                   duration  total_seconds  \\\n0      2  bible_human       0  0 days 00:00:12.000000000             12   \n1      3  bible_human       0  0 days 00:00:12.000000000             12   \n2      4  bible_human       0  0 days 00:07:19.000000000            439   \n\n  pair_id  reduced_label       WMD  glove_cosine  fasttext_cosine  \\\n0  pair_0             -1  0.423538      0.019526         0.036428   \n1  pair_0              0  0.423538      0.019526         0.036428   \n2  pair_0              1  0.423538      0.019526         0.036428   \n\n   POS Dist score  L2_score      bleu     bleu1  chrfScore  1-gram_overlap  \\\n0        1.358436  5.054252  0.574595  0.731549   0.705283        0.571429   \n1        1.358436  5.054252  0.574595  0.731549   0.705283        0.571429   \n2        1.358436  5.054252  0.574595  0.731549   0.705283        0.571429   \n\n    ROUGE-1   ROUGE-2   ROUGE-l  BertScore  \n0  0.758621  0.642857  0.727273   0.969994  \n1  0.758621  0.642857  0.727273   0.969994  \n2  0.758621  0.642857  0.727273   0.969994  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>annotator</th>\n      <th>text1</th>\n      <th>text2</th>\n      <th>label</th>\n      <th>dataset</th>\n      <th>random</th>\n      <th>duration</th>\n      <th>total_seconds</th>\n      <th>pair_id</th>\n      <th>reduced_label</th>\n      <th>WMD</th>\n      <th>glove_cosine</th>\n      <th>fasttext_cosine</th>\n      <th>POS Dist score</th>\n      <th>L2_score</th>\n      <th>bleu</th>\n      <th>bleu1</th>\n      <th>chrfScore</th>\n      <th>1-gram_overlap</th>\n      <th>ROUGE-1</th>\n      <th>ROUGE-2</th>\n      <th>ROUGE-l</th>\n      <th>BertScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A3BCGN11HDM8QR</td>\n      <td>and he sent eliakim who was over the household and shebna the scribe and the elders of the priests covered with sackcloth unto isaiah the prophet the son of amoz</td>\n      <td>and he sent eliakim who was over the house and shebna the scribe and the chief priests dressed in haircloth to isaiah the prophet the son of amoz</td>\n      <td>2</td>\n      <td>bible_human</td>\n      <td>0</td>\n      <td>0 days 00:00:12.000000000</td>\n      <td>12</td>\n      <td>pair_0</td>\n      <td>-1</td>\n      <td>0.423538</td>\n      <td>0.019526</td>\n      <td>0.036428</td>\n      <td>1.358436</td>\n      <td>5.054252</td>\n      <td>0.574595</td>\n      <td>0.731549</td>\n      <td>0.705283</td>\n      <td>0.571429</td>\n      <td>0.758621</td>\n      <td>0.642857</td>\n      <td>0.727273</td>\n      <td>0.969994</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A3SQ00HYQN7FYB</td>\n      <td>and he sent eliakim who was over the household and shebna the scribe and the elders of the priests covered with sackcloth unto isaiah the prophet the son of amoz</td>\n      <td>and he sent eliakim who was over the house and shebna the scribe and the chief priests dressed in haircloth to isaiah the prophet the son of amoz</td>\n      <td>3</td>\n      <td>bible_human</td>\n      <td>0</td>\n      <td>0 days 00:00:12.000000000</td>\n      <td>12</td>\n      <td>pair_0</td>\n      <td>0</td>\n      <td>0.423538</td>\n      <td>0.019526</td>\n      <td>0.036428</td>\n      <td>1.358436</td>\n      <td>5.054252</td>\n      <td>0.574595</td>\n      <td>0.731549</td>\n      <td>0.705283</td>\n      <td>0.571429</td>\n      <td>0.758621</td>\n      <td>0.642857</td>\n      <td>0.727273</td>\n      <td>0.969994</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A5WAWW70PYRP</td>\n      <td>and he sent eliakim who was over the household and shebna the scribe and the elders of the priests covered with sackcloth unto isaiah the prophet the son of amoz</td>\n      <td>and he sent eliakim who was over the house and shebna the scribe and the chief priests dressed in haircloth to isaiah the prophet the son of amoz</td>\n      <td>4</td>\n      <td>bible_human</td>\n      <td>0</td>\n      <td>0 days 00:07:19.000000000</td>\n      <td>439</td>\n      <td>pair_0</td>\n      <td>1</td>\n      <td>0.423538</td>\n      <td>0.019526</td>\n      <td>0.036428</td>\n      <td>1.358436</td>\n      <td>5.054252</td>\n      <td>0.574595</td>\n      <td>0.731549</td>\n      <td>0.705283</td>\n      <td>0.571429</td>\n      <td>0.758621</td>\n      <td>0.642857</td>\n      <td>0.727273</td>\n      <td>0.969994</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "DATA_PATH = PATH_ROOT / 'data'\n",
    "data_paths = [DATA_PATH / 'raw_data' / '*.csv', DATA_PATH / 'datasets' / '*.csv']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dct = {}\n",
    "for pth in data_paths:\n",
    "    pth = str(pth.resolve())\n",
    "    if 'raw' in pth:\n",
    "        for p in glob.glob(pth):\n",
    "            df = pd.read_csv(p, index_col=0)\n",
    "            dct[Path(p).stem] = {'columns': ', '.join(sorted(df.columns.tolist())),\n",
    "                                 'row_count': df.shape[0],\n",
    "                                 'values': ', '.join(sorted(df['Answer.semantic-similarity.label'].unique().tolist())),\n",
    "                                 'mean_annotations_per_pair': df.groupby(['Input.text1', 'Input.text2']).size().mean()}\n",
    "    else:\n",
    "        for p in glob.glob(pth):\n",
    "                df = pd.read_csv(p, index_col=0)\n",
    "                dct[Path(p).stem] = {'columns': ', '.join(sorted(df.columns.tolist())),\n",
    "                                     'row_count': df.shape[0],\n",
    "                                     'values': ', '.join(map(str, sorted(df['label'].unique().tolist()))),\n",
    "                                     'mean_annotations_per_pair': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df = pd.DataFrame.from_dict(dct, orient='index')\n",
    "datasets_df.to_csv(PATH_ROOT / 'data' / 'other' / 'datasets_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "          genres                                        text_1  \\\n0  main-captions                    a girl is styling her hair   \n1  main-captions       a group of men play soccer on the beach   \n2  main-captions  one woman is measuring another woman s ankle   \n3  main-captions                a man is cutting up a cucumber   \n4  main-captions                       a man is playing a harp   \n\n                                            text_2  label dataset  \\\n0                      a girl is brushing her hair    2.5     sts   \n1  a group of boys are playing soccer on the beach    3.6     sts   \n2           a woman measures another woman s ankle    5.0     sts   \n3                      a man is slicing a cucumber    4.2     sts   \n4                      a man is playing a keyboard    1.5     sts   \n\n  dataset-categ  pair_id       WMD  glove_cosine  fasttext_cosine  \\\n0      sts-test        0  1.101243      0.020379         0.072218   \n1      sts-test        1  0.813075      0.019756         0.035165   \n2      sts-test        2  0.845978      0.044791         0.050840   \n3      sts-test        3  1.116673      0.028424         0.048875   \n4      sts-test        4  1.726695      0.051076         0.108125   \n\n   POS Dist score  BertScore   L2_score          bleu     bleu1  chrfScore  \\\n0        0.000000   0.980371  10.471545  7.262123e-78  0.833333   0.641468   \n1        1.193633   0.981469   6.791739  3.799178e-01  0.700000   0.716334   \n2        0.000000   0.984674   8.400115  3.768499e-01  0.619198   0.635485   \n3        0.000000   0.976782   6.943588  6.147255e-78  0.705401   0.509810   \n4        3.129321   0.962170   7.255223  7.598357e-01  0.833333   0.747707   \n\n   1-gram_overlap   ROUGE-1   ROUGE-2   ROUGE-l  \n0        0.714286  0.833333  0.600000  0.833333  \n1        0.583333  0.736842  0.588235  0.736842  \n2        0.444444  0.666667  0.461538  0.615385  \n3        0.571429  0.769231  0.545455  0.727273  \n4        0.666667  0.833333  0.800000  0.800000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>genres</th>\n      <th>text_1</th>\n      <th>text_2</th>\n      <th>label</th>\n      <th>dataset</th>\n      <th>dataset-categ</th>\n      <th>pair_id</th>\n      <th>WMD</th>\n      <th>glove_cosine</th>\n      <th>fasttext_cosine</th>\n      <th>POS Dist score</th>\n      <th>BertScore</th>\n      <th>L2_score</th>\n      <th>bleu</th>\n      <th>bleu1</th>\n      <th>chrfScore</th>\n      <th>1-gram_overlap</th>\n      <th>ROUGE-1</th>\n      <th>ROUGE-2</th>\n      <th>ROUGE-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>main-captions</td>\n      <td>a girl is styling her hair</td>\n      <td>a girl is brushing her hair</td>\n      <td>2.5</td>\n      <td>sts</td>\n      <td>sts-test</td>\n      <td>0</td>\n      <td>1.101243</td>\n      <td>0.020379</td>\n      <td>0.072218</td>\n      <td>0.000000</td>\n      <td>0.980371</td>\n      <td>10.471545</td>\n      <td>7.262123e-78</td>\n      <td>0.833333</td>\n      <td>0.641468</td>\n      <td>0.714286</td>\n      <td>0.833333</td>\n      <td>0.600000</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>main-captions</td>\n      <td>a group of men play soccer on the beach</td>\n      <td>a group of boys are playing soccer on the beach</td>\n      <td>3.6</td>\n      <td>sts</td>\n      <td>sts-test</td>\n      <td>1</td>\n      <td>0.813075</td>\n      <td>0.019756</td>\n      <td>0.035165</td>\n      <td>1.193633</td>\n      <td>0.981469</td>\n      <td>6.791739</td>\n      <td>3.799178e-01</td>\n      <td>0.700000</td>\n      <td>0.716334</td>\n      <td>0.583333</td>\n      <td>0.736842</td>\n      <td>0.588235</td>\n      <td>0.736842</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>main-captions</td>\n      <td>one woman is measuring another woman s ankle</td>\n      <td>a woman measures another woman s ankle</td>\n      <td>5.0</td>\n      <td>sts</td>\n      <td>sts-test</td>\n      <td>2</td>\n      <td>0.845978</td>\n      <td>0.044791</td>\n      <td>0.050840</td>\n      <td>0.000000</td>\n      <td>0.984674</td>\n      <td>8.400115</td>\n      <td>3.768499e-01</td>\n      <td>0.619198</td>\n      <td>0.635485</td>\n      <td>0.444444</td>\n      <td>0.666667</td>\n      <td>0.461538</td>\n      <td>0.615385</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>main-captions</td>\n      <td>a man is cutting up a cucumber</td>\n      <td>a man is slicing a cucumber</td>\n      <td>4.2</td>\n      <td>sts</td>\n      <td>sts-test</td>\n      <td>3</td>\n      <td>1.116673</td>\n      <td>0.028424</td>\n      <td>0.048875</td>\n      <td>0.000000</td>\n      <td>0.976782</td>\n      <td>6.943588</td>\n      <td>6.147255e-78</td>\n      <td>0.705401</td>\n      <td>0.509810</td>\n      <td>0.571429</td>\n      <td>0.769231</td>\n      <td>0.545455</td>\n      <td>0.727273</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>main-captions</td>\n      <td>a man is playing a harp</td>\n      <td>a man is playing a keyboard</td>\n      <td>1.5</td>\n      <td>sts</td>\n      <td>sts-test</td>\n      <td>4</td>\n      <td>1.726695</td>\n      <td>0.051076</td>\n      <td>0.108125</td>\n      <td>3.129321</td>\n      <td>0.962170</td>\n      <td>7.255223</td>\n      <td>7.598357e-01</td>\n      <td>0.833333</td>\n      <td>0.747707</td>\n      <td>0.666667</td>\n      <td>0.833333</td>\n      <td>0.800000</td>\n      <td>0.800000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv(DATA_PATH / 'datasets' / 'sts.csv', index_col = 0)\n",
    "x.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Outliers\n",
    "\n",
    "Under the assumption that anyone that takes over the 95 percentile of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.total_seconds.describe(percentiles = [.25,.5,.75,.9,.95]))\n",
    "\n",
    "# ba = bad actor\n",
    "df['mean_annotation_time'] = df.groupby('annotator').total_seconds.transform('mean')\n",
    "print(df.mean_annotation_time.describe(percentiles = [.25,.5,.75,.9,.95]))\n",
    "ba_time = df[df.mean_annotation_time > 405].annotator.unique().tolist()\n",
    "print(len(df[df.total_seconds > 336].annotator.unique().tolist()))\n",
    "print(len(ba_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unvarianced Annotations\n",
    "Labelers whos std is too low mean non-random - random difference is too high  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelers = df[df.random==0].groupby(['annotator'])['label'].agg(['size','mean','std','min','max'])\n",
    "labelers = labelers[labelers['size']>1]\n",
    "#df = df[df.annotator.apply(lambda x:x in set(labelers.index))]\n",
    "\n",
    "labelers_rand = df[df.random==1].groupby(['annotator'])['label'].agg(['size','mean','std','min','max'])\n",
    "labelers_rand = labelers_rand[labelers_rand['size']>1]\n",
    "labelers = labelers.join(labelers_rand, rsuffix = '_rand')\n",
    "labelers['mean_random_gap'] = labelers['mean']-labelers['mean_rand']\n",
    "labelers['std_ratio'] = labelers['std']/labelers['std_rand']\n",
    "\n",
    "total_std = df.groupby('annotator')['label'].std()\n",
    "total_std.name = 'total_std'\n",
    "labelers = labelers.join(total_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_unvar_annotations = labelers[(labelers.total_std<1) & (labelers.mean_random_gap < 0)].index.tolist()\n",
    "len(ba_unvar_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpopular Annotators\n",
    "Those who over 50% of the time, disagree with the other annotators (in the reduced label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniquelabels = df.groupby(\"pair_id\")[\"reduced_label\"].nunique()\n",
    "pairs_twoagree = df_uniquelabels[(df.groupby(\"pair_id\")[\"reduced_label\"].nunique() == 2).values].index.tolist()\n",
    "df_twoagree = df[df[\"pair_id\"].isin(pairs_twoagree)]\n",
    "\n",
    "df_twoagree['generally_accepted_label'] = df_twoagree.groupby(\"pair_id\")['reduced_label'].transform('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twoagree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unpopularopinion = df_twoagree[df_twoagree.reduced_label != df_twoagree.generally_accepted_label].groupby('annotator').size().reset_index()\n",
    "df_unpopularopinion.columns = ['annotator','unpopular_opinion']\n",
    "\n",
    "df_allopinions = df[df['annotator'].isin(list(df_unpopularopinion.annotator))].groupby('annotator').size().reset_index()\n",
    "df_allopinions.columns = ['annotator','all_opinion']\n",
    "\n",
    "df_opinion_all_unpop = df_allopinions.merge(df_unpopularopinion,on=\"annotator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opinion_all_unpop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_unpopular = df_opinion_all_unpop[((df_opinion_all_unpop.unpopular_opinion / df_opinion_all_unpop.all_opinion) > 0.5) & (df_opinion_all_unpop.all_opinion > 4)].annotator.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment // Semantic Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis pipeline\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "text1_sent,text2_sent =[], []\n",
    "\n",
    "pbar = tqdm(total = len(df)//100+1, position = 0, leave = True)\n",
    "for i in range (len(df)//100+1):\n",
    "    t1_s = sentiment_pipe(df.text1.tolist()[100*i:np.min([100*i+100,len(df)])])\n",
    "    t2_s = sentiment_pipe(df.text2.tolist()[100*i:np.min([100*i+100,len(df)])])\n",
    "    text1_sent+=t1_s\n",
    "    text2_sent+=t2_s\n",
    "    pbar.update()\n",
    "pbar.close()\n",
    "len(text1_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = {'POSITIVE':1,'NEGATIVE':-1}\n",
    "\n",
    "df['sentiment_1'] = np.array([x['score']*sent[x['label']] for x in text1_sent]) \n",
    "df['sentiment_2'] = np.array([x['score']*sent[x['label']] for x in text2_sent])\n",
    "df['dif_sent'] =  np.abs(df['sentiment_1']-df['sentiment_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for index, row in df.iterrows():\n",
    "    first_sentence_tokens = row['text1'].strip().split()\n",
    "    second_sentence_tokens = row['text2'].strip().split()\n",
    "    pairs.append((first_sentence_tokens, second_sentence_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_bleu1 = []\n",
    "for first_sentence_tokens, second_sentence_tokens in pairs:\n",
    "\n",
    "    score_bleu1 = sentence_bleu([first_sentence_tokens], second_sentence_tokens, weights=(1, 0, 0, 0))\n",
    "    scores_bleu1.append(score_bleu1)\n",
    "\n",
    "print(np.mean(scores_bleu1))\n",
    "print(np.std(scores_bleu1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bleu_score_1'] = scores_bleu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_std_semantic = df[(df['bleu_score_1'] > 0.8) & (df['dif_sent'] > 1.9)].groupby('annotator')['label'].std().dropna()\n",
    "ba_semantics = list(annot_std_semantic[annot_std_semantic > 1.0].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ba = ['ba_semantics','ba_time','ba_unpopular','ba_unvar_annotations']\n",
    "\n",
    "for a,b in list(itertools.combinations(all_ba,2)):\n",
    "    print(f\"Jaccard Similarity of {a} and {b} is :{jaccard_similarity(eval(a),eval(b))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the overlap isn't super consistent, it is interesting to note that the two most correlated groups are time and unpopularity and unpopularity with unvaried annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ba = list(set(ba_unvar_annotations + ba_unpopular + ba_time + ba_semantics))\n",
    "print(f\"Total number of bad annotators are: {len(all_ba)}\")\n",
    "print(f\"Percentage of total annotators are: {len(all_ba)/df.annotator.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the annotators so we can filter them out quicker later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ba in all_ba:\n",
    "    with open(f'data/other/{ba}.txt', 'w') as f:\n",
    "        for item in eval(ba):\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/other/ba_all.txt','w') as f:\n",
    "    for item in list(set(ba_unvar_annotations + ba_unpopular + ba_time + ba_semantics)):\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "sota",
   "language": "python",
   "display_name": "SOTA"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}